{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "Building a linear regression model using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m6 packages\u001b[0m in 53ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install numpy torch lightgbm seaborn matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import lightgbm as lgb\n",
    "# import xgboost\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "# assigning data and target\n",
    "target = torch.from_numpy(train[\"FloodProbability\"].values)\n",
    "data = torch.from_numpy(train.drop([\"FloodProbability\", \"id\"], axis=1).values)\n",
    "\n",
    "X, y = data, target\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.float()\n",
    "y_train = y_train.float()\n",
    "X_test = X_test.float()\n",
    "y_test = y_test.float()\n",
    "\n",
    "# Create DataLoader for mini-batch training\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 50  # Adjust the batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "class MLP_Regressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Multilayer Perceptron for regression.\n",
    "    We have 20 features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(20, 32), nn.ReLU(), nn.Linear(32, 32), nn.ReLU(), nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function since I want to keep the loss metric consistent between my attempt and the kaggle check\n",
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "        ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "        r2 = 1 - ss_res / ss_tot\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize the MLP\n",
    "mlp = MLP_Regressor()\n",
    "model_1 = MLP_Regressor().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# X_train = X_train.to(device)\n",
    "# X_test = X_test.to(device)\n",
    "# y_train = y_train.to(device)\n",
    "# y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4301541575292302\n",
      "train loss: 0.4301546754112237\n",
      "train loss: 0.4301544646024437\n",
      "train loss: 0.4301566097782075\n",
      "train loss: 0.43015926345443095\n",
      "train loss: 0.4301551126663395\n",
      "train loss: 0.430154228346399\n",
      "train loss: 0.4301551173212863\n",
      "train loss: 0.43015504023476714\n",
      "train loss: 0.43015163916967847\n",
      "train loss: 0.43015601075785853\n",
      "train loss: 0.430155326100816\n",
      "train loss: 0.43015756396733373\n",
      "train loss: 0.4301538716831739\n",
      "train loss: 0.4301512080422987\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model_1\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move data to the correct device\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# inputs, targets = inputs.float(), targets.float()\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Documents/ML Projects/House Pricing/ml-housing/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/ML Projects/House Pricing/ml-housing/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/ML Projects/House Pricing/ml-housing/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/ML Projects/House Pricing/ml-housing/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/ML Projects/House Pricing/ml-housing/lib/python3.11/site-packages/torch/utils/data/dataset.py:206\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "File \u001b[0;32m~/Documents/ML Projects/House Pricing/ml-housing/lib/python3.11/site-packages/torch/utils/data/dataset.py:206\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Training and testing loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model_1.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Move data to the correct device\n",
    "        inputs, targets = data\n",
    "        # inputs, targets = inputs.float(), targets.float()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        targets = targets.unsqueeze(1)\n",
    "        # Forward pass\n",
    "        y_pred = model_1(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_pred, targets)\n",
    "\n",
    "        # Zero grad optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Step the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # if i % 10 == 0:\n",
    "        # print(\"Loss after mini-batch %5d: %.3f\" % (i + 1, train_loss / (i + 1)))\n",
    "        # train_loss = 0.0\n",
    "    print(f\"train loss: {train_loss/len(train_loader)}\")\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # ### Testing\n",
    "    # model_1.eval()\n",
    "    # test_loss = 0.0\n",
    "    # with torch.no_grad():\n",
    "    #     for inputs, targets in test_loader:\n",
    "    #         # Move data to the correct device\n",
    "    #         inputs, targets = inputs.to(device), targets.to(device)\n",
    "    #         targets = targets.unsqueeze(1)\n",
    "    #         # Forward pass\n",
    "    #         test_pred = model_1(inputs)\n",
    "\n",
    "    #         # Calculate loss\n",
    "    #         loss = loss_fn(test_pred, targets)\n",
    "    #         test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # if epoch % 1 == 0:\n",
    "    #     print(\n",
    "    #         f\"Epoch: {epoch + 1} | Train loss: {train_loss:.4f} | Test loss: {test_loss:.4f}\"\n",
    "    #     )\n",
    "\n",
    "    # Optionally clear cache if using GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('layers.0.weight',\n",
      "              tensor([[ 0.0174, -0.0439,  0.0675, -0.1616, -0.0335, -0.0080, -0.1872,  0.1829,\n",
      "          0.0683,  0.0632, -0.1320,  0.1208,  0.1210,  0.0828,  0.1114,  0.1583,\n",
      "          0.0076,  0.1274,  0.1629,  0.1641],\n",
      "        [ 0.1407, -0.0117, -0.2006, -0.1308,  0.0578,  0.0321,  0.1988, -0.0050,\n",
      "         -0.2047,  0.1641, -0.0992, -0.2001,  0.0563, -0.0228,  0.0564, -0.1967,\n",
      "          0.0754, -0.1655, -0.1286, -0.0569],\n",
      "        [ 0.1668,  0.0870,  0.1492, -0.1167,  0.0720, -0.1533, -0.1104,  0.0074,\n",
      "          0.1824, -0.0636, -0.2113,  0.0464,  0.2201, -0.1786,  0.2176, -0.0805,\n",
      "          0.0135, -0.0553, -0.0315,  0.0071],\n",
      "        [ 0.0596,  0.0144,  0.0861, -0.0594,  0.1180, -0.0905, -0.0499,  0.0715,\n",
      "         -0.0308,  0.1695,  0.1934,  0.2105, -0.2069,  0.1890, -0.0545, -0.0995,\n",
      "          0.2139, -0.0033, -0.1882,  0.0198],\n",
      "        [-0.1343,  0.1958,  0.1732, -0.0338, -0.1875, -0.0546, -0.1738,  0.1500,\n",
      "         -0.1858, -0.0701, -0.0109,  0.0625,  0.0964,  0.2059,  0.2206,  0.0150,\n",
      "          0.0360,  0.2191,  0.0167,  0.1283],\n",
      "        [-0.0336, -0.1026,  0.1137,  0.1073,  0.1426, -0.1742,  0.0684, -0.0418,\n",
      "         -0.1703,  0.2173,  0.1578, -0.1374,  0.0467,  0.1240, -0.1526, -0.2148,\n",
      "          0.0411, -0.1000,  0.0452,  0.1592],\n",
      "        [-0.0980, -0.1595, -0.1022, -0.1646,  0.1240,  0.1106, -0.1677, -0.1340,\n",
      "          0.0145,  0.1948, -0.0363,  0.0431,  0.2065,  0.0780,  0.1728,  0.0107,\n",
      "         -0.1478, -0.0533, -0.0908, -0.1951],\n",
      "        [-0.0114, -0.2030,  0.2015, -0.2027,  0.1930,  0.0898, -0.0018,  0.0986,\n",
      "          0.0280, -0.0336,  0.1975, -0.1807,  0.1172,  0.1498,  0.0323, -0.0338,\n",
      "         -0.1269, -0.0022, -0.1180, -0.0671],\n",
      "        [ 0.0408,  0.2029, -0.1068, -0.1536,  0.0866, -0.2093, -0.0069,  0.0720,\n",
      "         -0.1726,  0.0854,  0.0004,  0.2166,  0.1256,  0.1505,  0.1777, -0.0834,\n",
      "         -0.1245, -0.1949,  0.0142, -0.0531],\n",
      "        [-0.0247, -0.0341, -0.0482, -0.1209, -0.1894, -0.0926, -0.0661, -0.0920,\n",
      "          0.1641,  0.0919, -0.1168,  0.1217,  0.1488,  0.1830, -0.1280,  0.1746,\n",
      "         -0.0167, -0.1201, -0.1667, -0.0453],\n",
      "        [-0.1823, -0.1084, -0.0377, -0.1935,  0.0452,  0.1785, -0.1322,  0.0900,\n",
      "         -0.1955, -0.0068,  0.0459,  0.1221, -0.0968,  0.1237, -0.0824,  0.0666,\n",
      "         -0.1429, -0.0210,  0.0271,  0.1753],\n",
      "        [ 0.0633,  0.1572,  0.1637,  0.2061, -0.0337, -0.0214, -0.0195,  0.2008,\n",
      "         -0.1886, -0.0451, -0.1103,  0.0650,  0.1845,  0.0468,  0.1249, -0.0641,\n",
      "         -0.0431,  0.1472,  0.2116,  0.1247],\n",
      "        [-0.1326, -0.1632,  0.1393, -0.0245, -0.1958,  0.1773,  0.0929, -0.0003,\n",
      "          0.1481, -0.1787, -0.0243,  0.1981, -0.0939,  0.1232, -0.1767, -0.1839,\n",
      "         -0.0604,  0.1923,  0.1902, -0.0407],\n",
      "        [-0.0639,  0.1053,  0.0374, -0.2036,  0.1017, -0.1891, -0.0330,  0.0137,\n",
      "          0.0391,  0.0827,  0.0850,  0.2003, -0.0352, -0.2177, -0.1251, -0.1646,\n",
      "         -0.0416,  0.1577,  0.0896,  0.1777],\n",
      "        [ 0.0601,  0.0777,  0.0033,  0.1713,  0.1415, -0.0918, -0.2152, -0.0854,\n",
      "         -0.1512, -0.1230,  0.1376,  0.1905, -0.1978, -0.1096, -0.1722,  0.0441,\n",
      "         -0.0997,  0.2198, -0.1132, -0.1133],\n",
      "        [-0.0991,  0.0376, -0.1871, -0.1460,  0.1271, -0.1785, -0.1726,  0.2048,\n",
      "          0.0248, -0.0057,  0.1942,  0.0472, -0.1758, -0.1868, -0.0941, -0.0255,\n",
      "         -0.1007,  0.0256, -0.1922,  0.1259],\n",
      "        [ 0.1895, -0.1749,  0.2102, -0.1001, -0.0291, -0.1479, -0.1576,  0.1218,\n",
      "          0.2013, -0.1304, -0.0957, -0.1670, -0.0930, -0.0464,  0.0272, -0.1866,\n",
      "          0.0368,  0.1207, -0.2010,  0.1710],\n",
      "        [ 0.1743, -0.1995, -0.1419, -0.1070, -0.0087,  0.1476, -0.1488, -0.1785,\n",
      "         -0.0794, -0.1444, -0.0401, -0.0675, -0.1466, -0.1042,  0.0272, -0.2076,\n",
      "         -0.0201,  0.2016,  0.1685,  0.1658],\n",
      "        [-0.0945, -0.1179,  0.0273, -0.1451, -0.0088,  0.0824, -0.1681, -0.0484,\n",
      "          0.2063,  0.1421,  0.1687, -0.1330, -0.0941, -0.0875,  0.1510,  0.1540,\n",
      "          0.0270,  0.2163, -0.1641,  0.1217],\n",
      "        [ 0.2014, -0.1246,  0.1778, -0.1672,  0.0027,  0.1037, -0.2185, -0.0592,\n",
      "         -0.1828,  0.1552, -0.0705,  0.1535,  0.0511, -0.2228,  0.0262,  0.0418,\n",
      "         -0.0643,  0.0711, -0.1191, -0.0842],\n",
      "        [ 0.0397, -0.2080,  0.1916, -0.0287,  0.0700,  0.0153, -0.0625,  0.0380,\n",
      "          0.0716,  0.1422,  0.0231, -0.1969,  0.0409,  0.0014,  0.0064,  0.0864,\n",
      "         -0.2061,  0.1916,  0.0645,  0.1945],\n",
      "        [-0.0052,  0.0092,  0.0097, -0.0741, -0.0061,  0.0318, -0.0289, -0.0587,\n",
      "         -0.1288,  0.0688, -0.1958,  0.1098,  0.0948,  0.0786,  0.1865,  0.1576,\n",
      "          0.1552, -0.1033, -0.1005, -0.0145],\n",
      "        [-0.0842,  0.1130, -0.1601,  0.1769, -0.0729,  0.0358, -0.0274, -0.0275,\n",
      "          0.0993, -0.1150,  0.0205,  0.0214, -0.0416, -0.1365, -0.1673, -0.1559,\n",
      "         -0.0887, -0.1922, -0.2225,  0.1685],\n",
      "        [-0.0310, -0.0401, -0.1982,  0.1364, -0.0241,  0.0153,  0.0931,  0.0202,\n",
      "         -0.0579,  0.1055,  0.1211, -0.1261, -0.0192, -0.1253, -0.0780,  0.0690,\n",
      "          0.0390,  0.0901, -0.0505,  0.0446],\n",
      "        [ 0.1688,  0.0735, -0.1632, -0.0049, -0.1373, -0.1368,  0.1819, -0.1492,\n",
      "         -0.0364, -0.1467,  0.0226,  0.0047,  0.1186, -0.1423, -0.1472, -0.0193,\n",
      "          0.0465, -0.0302, -0.0325, -0.0755],\n",
      "        [-0.1816, -0.0644, -0.0371, -0.0384,  0.1239,  0.2047, -0.2119,  0.0111,\n",
      "         -0.0187,  0.1961,  0.1623, -0.0799, -0.0919,  0.0816, -0.0624,  0.0220,\n",
      "          0.1627, -0.1717,  0.0109,  0.1252],\n",
      "        [ 0.1354,  0.0897, -0.0931,  0.1955, -0.0954,  0.1330, -0.2204, -0.0935,\n",
      "         -0.1636, -0.0008,  0.1036,  0.0791,  0.2088, -0.0646, -0.2003,  0.0011,\n",
      "         -0.0603, -0.1425, -0.0622,  0.0259],\n",
      "        [ 0.0372,  0.0273, -0.1824, -0.1849,  0.0256,  0.1591, -0.0081, -0.1727,\n",
      "          0.1012,  0.2117, -0.0694, -0.0341, -0.0852, -0.0770,  0.2002,  0.1347,\n",
      "          0.0250,  0.0719,  0.0654, -0.1772],\n",
      "        [-0.0389,  0.0725, -0.1019,  0.0235,  0.0890,  0.0932, -0.1672, -0.1940,\n",
      "          0.0028, -0.0037, -0.0521, -0.0919, -0.0108,  0.0010, -0.0408, -0.1201,\n",
      "          0.0351, -0.0488,  0.1781,  0.0180],\n",
      "        [ 0.1880, -0.0207, -0.1822,  0.1718, -0.1528,  0.1535, -0.0564, -0.0989,\n",
      "         -0.1483,  0.0769, -0.0193,  0.0778,  0.1003,  0.0028,  0.1709, -0.1989,\n",
      "         -0.1806,  0.1593, -0.1295,  0.1740],\n",
      "        [ 0.1839,  0.1039, -0.1920, -0.1698,  0.0128, -0.1590, -0.1076, -0.1259,\n",
      "         -0.1732,  0.0929,  0.0555,  0.0559, -0.1160,  0.1354, -0.0977,  0.0341,\n",
      "          0.0265,  0.1973, -0.2132,  0.0928],\n",
      "        [-0.0322,  0.2022, -0.1141, -0.2172, -0.2206,  0.1736, -0.1889, -0.1334,\n",
      "         -0.1725, -0.0204,  0.0772, -0.0850,  0.2092,  0.1936, -0.0020,  0.1150,\n",
      "          0.0735,  0.1364, -0.1606, -0.1405]])),\n",
      "             ('layers.0.bias',\n",
      "              tensor([-0.1065, -0.0640,  0.0265, -0.0558, -0.0261, -0.1507, -0.0104,  0.0107,\n",
      "         0.0555,  0.0828, -0.1153, -0.1089, -0.1826,  0.1058, -0.0135,  0.1632,\n",
      "        -0.1226,  0.1395,  0.1843, -0.1297,  0.0619,  0.1421,  0.0007,  0.1698,\n",
      "         0.0769, -0.0855,  0.0523,  0.2224, -0.2026,  0.1747,  0.1808,  0.0041])),\n",
      "             ('layers.2.weight',\n",
      "              tensor([[-0.1455,  0.1751,  0.0893,  ..., -0.0441, -0.0998,  0.0340],\n",
      "        [ 0.0641, -0.0297,  0.1092,  ..., -0.1321,  0.1646,  0.1095],\n",
      "        [-0.1427, -0.1396,  0.0338,  ...,  0.1708, -0.1167, -0.0728],\n",
      "        ...,\n",
      "        [ 0.1151,  0.0316, -0.0668,  ..., -0.0397,  0.1251, -0.0353],\n",
      "        [ 0.1021,  0.1461, -0.0619,  ..., -0.0457, -0.1065, -0.0530],\n",
      "        [-0.0501, -0.0505, -0.0366,  ..., -0.0483, -0.1388, -0.1627]])),\n",
      "             ('layers.2.bias',\n",
      "              tensor([-0.0096, -0.0552,  0.0463, -0.1537,  0.0720, -0.1304,  0.1382,  0.1288,\n",
      "        -0.0323, -0.1686, -0.1093,  0.1043, -0.0552, -0.1259, -0.1287,  0.0581,\n",
      "         0.0861,  0.0083, -0.0629, -0.0360, -0.0296,  0.0270, -0.0359, -0.0040,\n",
      "        -0.0268, -0.1219,  0.1734, -0.1210,  0.0196,  0.0184, -0.0790,  0.0440])),\n",
      "             ('layers.4.weight',\n",
      "              tensor([[ 0.0930, -0.0222,  0.0784, -0.1334,  0.0596,  0.1047,  0.0767,  0.1211,\n",
      "          0.0130,  0.1158, -0.0569, -0.1067,  0.0631, -0.0132,  0.0859, -0.0938,\n",
      "          0.1177,  0.0642,  0.1738,  0.0343,  0.1138, -0.0281, -0.1548, -0.1623,\n",
      "          0.0848, -0.0656,  0.0439, -0.0347, -0.0030,  0.1534, -0.0590, -0.0094]])),\n",
      "             ('layers.4.bias', tensor([0.0139]))])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "pprint(model_1.state_dict())\n",
    "# print(\"\\nAnd the original values for weights and bias are:\")\n",
    "# print(f\"weights: {weight}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test_cleaned = test.drop([\"id\"], axis=1)\n",
    "test_cleaned = torch.from_numpy(test_cleaned.values)\n",
    "test_cleaned = test_cleaned.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(\"data/test.csv\")\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_1(test_cleaned)\n",
    "y_preds\n",
    "\n",
    "df = pd.DataFrame(y_preds.numpy())\n",
    "\n",
    "df1 = pd.merge(test[\"id\"], df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={\"O\": \"FloodProbability\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df1.columns.tolist()\n",
    "column_names[1] = \"FloodProbability\"\n",
    "df1.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.237746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.384492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.345836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.163628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.332582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745300</th>\n",
       "      <td>1863257</td>\n",
       "      <td>0.384192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745301</th>\n",
       "      <td>1863258</td>\n",
       "      <td>0.223839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745302</th>\n",
       "      <td>1863259</td>\n",
       "      <td>0.423804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745303</th>\n",
       "      <td>1863260</td>\n",
       "      <td>0.597693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745304</th>\n",
       "      <td>1863261</td>\n",
       "      <td>0.338004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>745305 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  FloodProbability\n",
       "0       1117957          0.237746\n",
       "1       1117958          0.384492\n",
       "2       1117959          0.345836\n",
       "3       1117960          0.163628\n",
       "4       1117961          0.332582\n",
       "...         ...               ...\n",
       "745300  1863257          0.384192\n",
       "745301  1863258          0.223839\n",
       "745302  1863259          0.423804\n",
       "745303  1863260          0.597693\n",
       "745304  1863261          0.338004\n",
       "\n",
       "[745305 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"new2_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-housing_kernel",
   "language": "python",
   "name": "ml-housing_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
